---
title: Jan
description: Working towards open superintelligence through community-driven AI
keywords:
  [
    Jan,
    Jan AI,
    open superintelligence,
    AI ecosystem,
    local AI,
    private AI,
    self-hosted AI,
    llama.cpp,
    Model Context Protocol,
    MCP,
    GGUF models,
    large language model,
    LLM,
  ]
---

import { Callout } from 'nextra/components'
import FAQBox from '@/components/FaqBox'

# Jan

![Jan's Cover Image](./_assets/jan-app-new.png)

## Jan's Goal

> We're working towards open superintelligence to make a viable open-source alternative to platforms like ChatGPT
and Claude that anyone can own and run.

## What is Jan Today

Jan is an open-source AI platform that runs on your hardware. We believe AI should be in the hands of many, not
controlled by a few tech giants.

Today, Jan is:
- **A desktop app** that runs AI models locally or connects to cloud providers
- **A model hub** making the latest open-source models accessible
- **A connector system** that lets AI interact with real-world tools via MCP

Tomorrow, Jan aims to be a complete ecosystem where open models rival or exceed closed alternatives.

<Callout type="info">
We're building this with the open-source AI community, using the best available tools, and sharing everything
we learn along the way.
</Callout>

## The Jan Ecosystem

### Jan Apps
**Available Now:**
- **Desktop**: Full-featured AI workstation for Windows, Mac, and Linux

**Coming Late 2025:**
- **Mobile**: Jan on your phone
- **Web**: Browser-based access at jan.ai
- **Server**: Self-hosted for teams
- **Extensions**: Browser extension for Chrome-based browsers

### Jan Model Hub
Making open-source AI accessible to everyone:
- **Easy Downloads**: One-click model installation
- **Jan Models**: Our own models optimized for local use
  - **Jan-v1**: 4B reasoning model specialized in web search
  - **Research Models**
    - **Jan-Nano (32k/128k)**: 4B model for web search with MCP tools
    - **Lucy**: 1.7B mobile-optimized for web search
- **Community Models**: Any GGUF from Hugging Face works in Jan
- **Cloud Models**: Connect your API keys for OpenAI, Anthropic, Gemini, and more


### Jan Connectors Hub
Connect AI to the tools you use daily via [Model Context Protocol](./mcp):

**Creative & Design:**
- **Canva**: Generate and edit designs

**Data & Analysis:**
- **Jupyter**: Run Python notebooks
- **E2B**: Execute code in sandboxes

**Web & Search:**
- **Browserbase & Browser Use**: Browser automation
- **Exa, Serper, Perplexity**: Advanced web search
- **Octagon**: Deep research capabilities

**Productivity:**
- **Linear**: Project management
- **Todoist**: Task management

## Core Features

- **Run Models Locally**: Download any GGUF model from Hugging Face, use OpenAI's gpt-oss models,
or connect to cloud providers
- **OpenAI-Compatible API**: Local server at `localhost:1337` works with tools like
[Continue](./server-examples/continue-dev) and [Cline](https://cline.bot/)
- **Extend with MCP Tools**: Browser automation, web search, data analysis, and design tools, all
through natural language
- **Your Choice of Infrastructure**: Run on your laptop, self-host on your servers (soon), or use
cloud when you need it

## Philosophy

Jan is built to be user-owned:
- **Open Source**: Apache 2.0 license
- **Local First**: Your data stays on your device. Internet is optional
- **Privacy Focused**: We don't collect or sell user data. See our [Privacy Policy](./privacy)
- **No Lock-in**: Export your data anytime. Use any model. Switch between local and cloud

<Callout>
The best AI is the one you control. Not the one that others control for you.
</Callout>

## The Path Forward

### What Works Today
- Run powerful models locally on consumer hardware
- Connect to any cloud provider with your API keys
- Use MCP tools for real-world tasks
- Access transparent model evaluations

### What We're Building
- More specialized models that excel at specific tasks
- Expanded app ecosystem (mobile, web, extensions)
- Richer connector ecosystem
- An evaluation framework to build better models

### The Long-Term Vision
We're working towards open superintelligence where:
- Open models match or exceed closed alternatives
- Anyone can run powerful AI on their own hardware
- The community drives innovation, not corporations
- AI capabilities are owned by users, not rented

<Callout type="warning">
This is an ambitious goal without a guaranteed path. We're betting on the open-source community, improved
hardware, and better techniques, but we're honest that this is a journey, not a destination we've reached.
</Callout>

## Quick Start

1. [Download Jan](./quickstart) for your operating system
2. Choose a model - download locally or add cloud API keys
3. Start chatting or connect tools via MCP
4. Build with our [local API](./api-server)

## Acknowledgements

Jan is built on the shoulders of giants:
- [Llama.cpp](https://github.com/ggerganov/llama.cpp) for inference
- [Model Context Protocol](https://modelcontextprotocol.io) for tool integration
- The open-source community that makes this possible

## FAQs

<FAQBox title="What is Jan?">
  Jan is an open-source AI platform working towards a viable alternative to Big Tech AI. Today it's a desktop app that runs models locally or connects to cloud providers. Tomorrow it aims to be a complete ecosystem rivaling platforms like ChatGPT and Claude.
</FAQBox>

<FAQBox title="How is this different from other AI platforms?">
  Other platforms are models behind APIs you rent. Jan is a complete AI ecosystem you own. Run any model, use real tools through MCP, keep your data private, and never pay subscriptions for local use.
</FAQBox>

<FAQBox title="What models can I use?">
  **Jan Models:**
  - Jan-Nano (32k/128k) - Research and analysis with MCP integration
  - Lucy - Mobile-optimized search (1.7B)
  - Jan-v1 - Reasoning and tool use (4B)

  **Open Source:**
  - OpenAI's gpt-oss models (120b and 20b)
  - Any GGUF model from Hugging Face

  **Cloud (with your API keys):**
  - OpenAI, Anthropic, Mistral, Groq, and more
</FAQBox>

<FAQBox title="What are MCP tools?">
  MCP (Model Context Protocol) lets AI interact with real applications. Instead of just generating text, your AI can create designs in Canva, analyze data in Jupyter, browse the web, and execute code - all through conversation.
</FAQBox>

<FAQBox title="Is Jan compatible with my system?">
  **Supported OS**:
  - [Windows 10+](/docs/desktop/windows#compatibility)
  - [macOS 12+](/docs/desktop/mac#compatibility)
  - [Linux (Ubuntu 20.04+)](/docs/desktop/linux)

  **Hardware**:
  - Minimum: 8GB RAM, 10GB storage
  - Recommended: 16GB RAM, GPU (NVIDIA/AMD/Intel/Apple), 50GB storage
</FAQBox>

<FAQBox title="How realistic is 'open superintelligence'?">
  Honestly? It's ambitious and uncertain. We believe the combination of rapidly improving open models, better consumer hardware, community innovation, and specialized models working together can eventually rival closed platforms. But this is a multi-year journey with no guarantees. What we can guarantee is that we'll keep building in the open, with the community, towards this goal.
</FAQBox>

<FAQBox title="What can Jan actually do today?">
  Right now, Jan can:
  - Run models like Llama, Mistral, and our own Jan models locally
  - Connect to cloud providers if you want more power
  - Use MCP tools to create designs, analyze data, browse the web, and more
  - Work completely offline once models are downloaded
  - Provide an OpenAI-compatible API for developers
</FAQBox>

<FAQBox title="Is Jan really free?">
  **Local use**: Always free, no catches
  **Cloud models**: You pay providers directly (we add no markup)
  **Jan cloud**: Optional paid services coming 2025

  The core platform will always be free and open source.
</FAQBox>

<FAQBox title="How does Jan protect privacy?">
  - Runs 100% offline once models are downloaded
  - All data stored locally in [Jan Data Folder](/docs/data-folder)
  - No telemetry without explicit consent
  - Open source code you can audit

  <Callout type="warning">
    When using cloud providers through Jan, their privacy policies apply.
  </Callout>
</FAQBox>

<FAQBox title="Can I self-host Jan?">
  Yes. Download directly or build from [source](https://github.com/menloresearch/jan). Jan Server for production deployments coming late 2025.
</FAQBox>

<FAQBox title="When will mobile/web versions launch?">
  - **Jan Web**: Beta late 2025
  - **Jan Mobile**: Late 2025
  - **Jan Server**: Late 2025

  All versions will sync seamlessly.
</FAQBox>

<FAQBox title="How can I contribute?">
  - Code: [GitHub](https://github.com/menloresearch/jan)
  - Community: [Discord](https://discord.gg/FTk2MvZwJH)
  - Testing: Help evaluate models and report bugs
  - Documentation: Improve guides and tutorials
</FAQBox>

<FAQBox title="Are you hiring?">
  Yes! We love hiring from our community. Check [Careers](https://menlo.bamboohr.com/careers).
</FAQBox>
